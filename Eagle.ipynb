{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa46b483-4303-449a-be7b-9012dc09071b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Data/bd_gid_map_RP_202211041511.csv',\n",
       " './Data/RP_truedemand.csv',\n",
       " './Data/model_base_RP_PH_3category.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date, timedelta, datetime, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "import os, gc, re; \n",
    "from glob import glob\n",
    "gc.enable();\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from random import randint\n",
    "from numba import jit\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "\n",
    "import unittest\n",
    "import logging\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "glob(\"./Data/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = False\n",
    "if normalize:\n",
    "    truedf = pd.read_csv([i for i in glob(\"./Data/*.csv\") if 'true' in i ][0], parse_dates=[\"report_date\"],\n",
    "                         converters={'qty': lambda u: np.log1p(float(u)) if float(u) > 0 else 0.1})\n",
    "else:\n",
    "    truedf = pd.read_csv([i for i in glob(\"./Data/*.csv\") if 'true' in i ][0], parse_dates=[\"report_date\"])\n",
    "    \n",
    "basedf = pd.read_csv([i for i in glob(\"./Data/*.csv\") if 'base' in i ][0], parse_dates=[\"fcst_date\"])\n",
    "gid_map = pd.read_csv([i for i in glob(\"./Data/*.csv\") if 'map' in i ][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449aa31e-ca71-40f3-a083-ccf78ca363a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Forecate_months = 3\n",
    "preparation_period = 2\n",
    "base_car = ['CATEGORY','CATEGORY_DETAIL','PRDTLN','MODEL']\n",
    "base_var = ['PN','CATEGORY','CATEGORY_DETAIL','PRDTLN','STDCOST_USD','MODEL']\n",
    "\n",
    "start_date = str(sorted(truedf.report_date)[0])\n",
    "simulation = sorted([i for i in set(list(basedf.fcst_date)) if i > date(2021, 10, 31) ])\n",
    "train_period = simulation[0] +  relativedelta(months= -21)\n",
    "prediction_period = str(simulation[-1] +  relativedelta(months=preparation_period ) + relativedelta(months= Forecate_months))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_param= {'reg:squarederror':'rmse','reg:squaredlogerror':'rmsle','reg:pseudohubererror':'mphe', \n",
    "         'reg:gamma':'gamma-deviance','reg:tweedie':'tweedie-nloglik','count:poisson':'poisson-nloglik'}\n",
    "\n",
    "class CFG:\n",
    "    __slots__ = ['booster','obj','huber_slope','rate_drop','max_depth', 'tree_method', 'l_rate', 'subsample','col_sample',\n",
    "                 'l2','num_threads','eval_metric','importance_type','num_boost_round','early_stop','verbose_eval',\n",
    "                 'verbose','max_bin']\n",
    "    def __init__(self):\n",
    "        self.obj = 'reg:pseudohubererror'\n",
    "        self.huber_slope = 0.15\n",
    "        self.max_depth =  5\n",
    "        self.tree_method = 'gpu_hist'\n",
    "        self.l_rate = 0.07\n",
    "        self.subsample = 0.85\n",
    "        self.col_sample = 0.75\n",
    "        self.max_bin = 512\n",
    "        self.l2 = 0.9\n",
    "        self.rate_drop = 0.3\n",
    "        self.num_threads = 15\n",
    "        self.eval_metric = reg_param[self.obj]\n",
    "        self.importance_type = 'total_gain'\n",
    "        self.num_boost_round = 500000\n",
    "        self.early_stop = 1000\n",
    "        self.verbose_eval = 5000\n",
    "        self.verbose = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea59e60-8741-4bbd-a6c3-f5fb117f4326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestMethods(unittest.TestCase):\n",
    "    \n",
    "    def test_isInstance(self):\n",
    "        message = \"given object is not instance of My definition.\"\n",
    "        self.assertIsInstance(pd.DataFrame(), type(truedf), message)\n",
    "        \n",
    "    def test_trainingDate(self):\n",
    "        self.assertGreaterEqual(train_period, truedf.report_date.min())\n",
    "    \n",
    "    def test_isMember(self):\n",
    "        for i in base_var:\n",
    "            self.assertIn(i, basedf.columns)\n",
    "            \n",
    "    def test_Params(self):\n",
    "        test = CFG()\n",
    "        self.assertIsInstance(test.obj, str)\n",
    "        self.assertIsInstance(test.eval_metric, str)\n",
    "        self.assertGreaterEqual(os.cpu_count(), test.num_threads)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e23531df-1832-467c-9dfd-1d8afa9b10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name:str):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'{name} done in {time.time() - t0:.3f} sec')\n",
    "    print(f'{name} done in {(time.time() - t0)/60} min')\n",
    "    \n",
    "@jit\n",
    "def smape(y_true, y_pred):\n",
    "    return 200 * sum(np.abs(y_true - y_pred))/sum(np.abs(y_true) + np.abs(y_pred))/len(y_true)\n",
    "@jit\n",
    "def mape_val(y_true, y_pred):\n",
    "    return sum(np.abs(y_true - y_pred))/sum(y_true) \n",
    "\n",
    "def preprocess(base:pd.DataFrame, truedf:pd.DataFrame, base_car:list):   \n",
    " \n",
    "    base['PN'] = base['PN'].apply(lambda x: str(x).replace(\"|\", \" \").split())\n",
    "    base = base.explode('PN')\n",
    "    base['STDCOST_USD'] = base['STDCOST_USD'].apply(lambda x: int(x)) \n",
    "    base_pn = base[base_var]\n",
    "    base_car = base_car\n",
    "    le = LabelEncoder()\n",
    "    for i in base_car:\n",
    "        base_pn[i] = le.fit_transform(base_pn[i].values)\n",
    "    base_pn = base_pn.drop_duplicates()\n",
    "    base_pn = base_pn.set_index('PN')\n",
    "    \n",
    "    truedf.rename(columns={'pn': 'PN'}, inplace=True)\n",
    "    dates = pd.date_range(start=start_date, end = prediction_period, freq='1D')\n",
    "    \n",
    "    df = base_pn.merge(truedf, on='PN', how='left')\n",
    "    df = df.groupby(['PN', pd.Grouper(key='report_date', freq='1M')])['qty'].sum().unstack(level=-1).fillna(0)\n",
    "    df = df.T.reindex(dates).T.fillna(0)\n",
    "    df2 = df.join(base_pn)\n",
    "    assert df.shape[0] == df2.shape[0],\"shape should be the same\"\n",
    "    \n",
    "    return df, df2\n",
    "\n",
    "def post_pro(test_pred, df, t_val_begin, Forecate_months, walk_target, normalize = False):\n",
    "    sub = np.array(test_pred).clip(0.).transpose()\n",
    "    df_sub = pd.DataFrame(sub, index=df.index,\n",
    "        columns=pd.date_range(t_fcst_begin, periods=walk_target, freq = '1M')).stack().to_frame(\"qty\")\n",
    "    if normalize:\n",
    "        df_sub[\"qty\"] =np.expm1(df_sub[\"qty\"]).clip(0.)\n",
    "\n",
    "    dd = df_sub.unstack(level=-1)\n",
    "    dd.columns = dd.columns.get_level_values(1)\n",
    "    dd = dd.reset_index()\n",
    "    dd.columns=[ \"M\"+str(i) for i in range(0, Forecate_months + 1)]\n",
    "    dd.rename(columns={'M0':'PN'},inplace=True)\n",
    "    dd['fsct_date'] = str(t_val_begin  +  relativedelta(months=walk_target))\n",
    "    print(f\"Datas fsct_date { str(t_val_begin  +  relativedelta(months=walk_target))}\")\n",
    "\n",
    "    return dd\n",
    "   \n",
    "def simu(gid_map, result, postfix='baby'):\n",
    "    gid_map.rename(columns={'pn':'PN'},inplace=True)\n",
    "    sub_final = gid_map.merge(result, on='PN')\n",
    "    final_list = ['gid','fsct_date']\n",
    "    b = ['M'+ str(i) for i in range(1, Forecate_months + 1)]\n",
    "    final_list.extend(b)\n",
    "    sub_final = sub_final[final_list]\n",
    "    \n",
    "    sim = sub_final.groupby(['gid','fsct_date'])[['M1']].sum().reset_index()\n",
    "    \n",
    "    for i in range(2, Forecate_months + 1):\n",
    "        sim = sim.merge(sub_final.groupby(['gid','fsct_date'])[['M'+ str(i)]].sum().reset_index(), on =['gid','fsct_date'])\n",
    "    \n",
    "    for i in range(1, Forecate_months + 1):\n",
    "        sim['M'+ str(i)] = sim['M'+ str(i)].round(4)\n",
    "\n",
    "    sim.to_csv(f'Test_sim_{postfix}.csv', float_format='%.4f', index=None, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "357ba6e4-401a-442f-a410-cf00857d2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, dt, minus, periods, freq ='1M'):\n",
    "    return df[pd.date_range(dt - relativedelta(months=minus), periods=periods, freq=freq)]\n",
    "\n",
    "\n",
    "def prepare_dataset(df, t_begin, is_train=True, name_prefix=None, target=2):\n",
    "    X = {}\n",
    "    \n",
    "    for i in range(1, 13, 3):    \n",
    "        curr =  get_timespan(df, t_begin, i, 1).values.ravel()\n",
    "        X[f'AC_{i}'] = sm.tsa.acf(curr, nlags= (len(curr)-1))\n",
    "            \n",
    "    for i in range(1, 13):\n",
    "        X[f'mon_{i}'] = get_timespan(df, t_begin, i, 1).values.ravel()\n",
    "    \n",
    "    for i in [ 3, 6, 9, 12]:\n",
    "        tmp = get_timespan(df, t_begin, i, i)\n",
    "        X[f'diff_{i}_mean'] = tmp.diff(axis=1).mean(axis=1).values \n",
    "        X[f'mean_{i}_decay'] = (tmp * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "        X[f'mean_{i}'] = tmp.mean(axis=1).values\n",
    "        X[f'median_{i}'] = tmp.median(axis=1).values\n",
    "        X[f'min_{i}'] = tmp.min(axis=1).values\n",
    "        X[f'max_{i}'] = tmp.max(axis=1).values\n",
    "        X[f'std_{i}'] = tmp.std(axis=1).values\n",
    "        X[f'zero_{i}'] = (tmp == 0).astype(int).sum(axis=1)\n",
    "        \n",
    "\n",
    "    \n",
    "    for i in [ 3, 6, 9, 12]:\n",
    "        tmp = get_timespan(df, t_begin, i, i) \n",
    "        X[f'has_sales_days_in_last_{i}'] = (tmp > 0).sum(axis=1).values\n",
    "        X[f'last_has_sales_day_in_last_{i}' ] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values\n",
    "        X[f'first_has_sales_day_in_last_{i}'] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "    for i in range(3):\n",
    "        X[f'mean_3M_sea_{i}'] = get_timespan(df, t_begin, 12-i, 4, freq='3M').mean(axis=1).values\n",
    "        X[f'mean_6M_sea_{i}'] = get_timespan(df, t_begin, 12-i, 2, freq='6M').mean(axis=1).values\n",
    "        X[f'mean_12M_sea_{i}'] = get_timespan(df, t_begin, 24-i, 2, freq='12M').mean(axis=1).values\n",
    "\n",
    "    X = pd.DataFrame(X)\n",
    "    gc.collect();   \n",
    "    \n",
    "    if is_train:\n",
    "        y = df[pd.date_range(t_begin, periods = target, freq = '1M')].values\n",
    "        return X, y\n",
    "    \n",
    "    if name_prefix is not None:\n",
    "        X.columns = ['%s_%s' % (name_prefix, c) for c in X.columns]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing done in 0.609 sec\n",
      "processing done in 0.010150444507598878 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "with timer('processing'):\n",
    "    df, df2 = preprocess(basedf, truedf, base_car)\n",
    "    \n",
    "class TestMethods(unittest.TestCase):\n",
    "    \n",
    "    def test_isInstance(self):\n",
    "        message = \"given object is not instance of My definition.\"\n",
    "        self.assertIsInstance(pd.DataFrame(), type(df), message)\n",
    "        self.assertIsInstance(pd.DataFrame(), type(df2), message)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 12:35:37\n",
      "Preparing dataset...\n",
      "================================================================================\n",
      "Simulation 2021-11-30 00:00:00\n",
      "================================================================================\n",
      "Training set start date: 2020-02-29 00:00:00\n",
      "Training set   end date: 2021-08-29 00:00:00\n",
      "Validation set start date: 2021-08-29 00:00:00\n",
      "Validation set   end date: 2021-11-29 00:00:00\n",
      "Forecasting set start date: 2022-01-29 00:00:00\n",
      "Forecasting set   end date: 2022-04-29 00:00:00\n",
      "a-enet set start date: 2020-02-29 00:00:00\n",
      "a-enet set   end date: 2021-11-29 00:00:00\n",
      "\n",
      "(14155, 74) (16390, 74) (745, 74)\n",
      "================================================================================\n",
      "Step 1\n",
      "================================================================================\n",
      "[0]\ttrain-mphe:1.33329\teval-mphe:1.68842\n",
      "[5000]\ttrain-mphe:0.11438\teval-mphe:0.03154\n"
     ]
    }
   ],
   "source": [
    "current_time = (datetime.now() + relativedelta(hours = 8)).strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "with timer('Training Total Execution time'):\n",
    "    print(\"Preparing dataset...\")\n",
    "\n",
    "    gc.enable()\n",
    "    df_concat = df2[base_var[1:]]\n",
    "\n",
    "    interval = 1\n",
    "    walk_target = Forecate_months\n",
    "    \n",
    "    t_begin = train_period\n",
    "\n",
    "    frames_alpha = []\n",
    "    score_mse = []\n",
    "    for si in simulation:\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Simulation {str(si)}\" )\n",
    "        print(\"=\" * 80)\n",
    "        num_months = relativedelta(si, t_begin).years*12 + relativedelta(si, t_begin).months - walk_target\n",
    "        t_val_begin = t_begin + relativedelta(months=(num_months)*interval ) \n",
    "        t_fcst_begin = t_val_begin + relativedelta(months= walk_target + preparation_period )\n",
    "\n",
    "        X_l, y_l = [], []\n",
    "        X_2, y_2 = [], []\n",
    "        logging.basicConfig(filename='myprepare.log',  level=logging.DEBUG)\n",
    "        logging.info('Started')\n",
    "        for i in range(num_months + 1):\n",
    "            delta = relativedelta(months=interval * i ) \n",
    "            X_tmp, y_tmp = prepare_dataset(df, t_begin + delta, target = walk_target)\n",
    "            X_tmp = pd.concat([X_tmp, df_concat], join='inner', axis=1)\n",
    "            X_l.append(X_tmp)\n",
    "            y_l.append(y_tmp)\n",
    "            \n",
    "        for k in range(num_months + 1 + walk_target): \n",
    "            delta_bat = relativedelta(months=interval * k ) \n",
    "            X_batmp, y_batmp = prepare_dataset(df, t_begin + delta_bat, target = walk_target)\n",
    "            X_batmp = pd.concat([X_batmp, df_concat], join='inner', axis=1)\n",
    "            X_2.append(X_batmp)\n",
    "            y_2.append(y_batmp)\n",
    "            \n",
    "        \n",
    "        X_train = pd.concat(X_l, axis=0)\n",
    "        y_train = np.concatenate(y_l, axis=0)\n",
    "        print(f'Training set start date: {t_begin}')\n",
    "        print(f'Training set   end date: {t_begin + delta}')\n",
    "\n",
    "        X_val, y_val = prepare_dataset(df, t_val_begin, target = walk_target )\n",
    "        X_val = pd.concat([X_val, df_concat], join='inner', axis=1)\n",
    "\n",
    "        print(f'Validation set start date: {t_val_begin}')\n",
    "        print(f'Validation set   end date: {t_val_begin  +  relativedelta(months=walk_target)}')\n",
    "\n",
    "        X_test = prepare_dataset(df, t_fcst_begin, is_train=False, target = walk_target)\n",
    "        X_test = pd.concat([X_test, df_concat], join='inner', axis=1)\n",
    "        print(f'Forecasting set start date: {t_fcst_begin}')\n",
    "        print(f'Forecasting set   end date: {t_fcst_begin  +  relativedelta(months=walk_target)}')\n",
    "        \n",
    "        X_bat = pd.concat(X_2, axis=0)\n",
    "        y_bat = np.concatenate(y_2, axis=0)\n",
    "        print(f'a-enet set start date: {t_begin}')\n",
    "        print(f'a-enet set   end date: {t_begin + delta_bat }\\n')\n",
    "        assert X_train.shape[0] != X_bat.shape[0],\"shape should Not be the same\"\n",
    "        print(X_train.shape,  X_bat.shape, X_val.shape)\n",
    "        del X_l, y_l, X_2, y_2; gc.collect();\n",
    "        logging.info('Finished')\n",
    "        \n",
    "        par = CFG()\n",
    "        params = {\n",
    "            'objective': par.obj,\n",
    "            'max_depth': par.max_depth,\n",
    "            'max_bin':par.max_bin,\n",
    "            'tree_method': par.tree_method,\n",
    "            'learning_rate': par.l_rate,\n",
    "            'subsample': par.subsample,\n",
    "            'colsample_bytree':par.col_sample,\n",
    "            'lambda':par.l2,\n",
    "            'eval_metric': par.eval_metric,\n",
    "            'nthread': par.num_threads,\n",
    "            'verbosity': par.verbose\n",
    "        }\n",
    "        \n",
    "\n",
    "        val_pred = []\n",
    "        test_alpha_pred = []\n",
    "        cate_vars = base_car\n",
    "        for walk in range(walk_target):\n",
    "            print(\"=\" * 80)\n",
    "            print(f\"Step {walk + 1}\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            early_stop  = xgb.callback.EarlyStopping(\n",
    "                            rounds=par.early_stop,\n",
    "                            metric_name=par.eval_metric,\n",
    "                            maximize = False,\n",
    "                            save_best = False,\n",
    "                            min_delta = 1e-5,\n",
    "                            data_name = \"eval\")\n",
    "            \n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train[:, walk], missing=np.NaN, enable_categorical=True) \n",
    "            dval = xgb.DMatrix(X_val, label=y_val[:, walk], missing=np.NaN, enable_categorical=True)\n",
    "            dtest = xgb.DMatrix(X_test, missing=np.NaN, enable_categorical=True)\n",
    "            bst = xgb.train( params, dtrain, num_boost_round=par.num_boost_round,\n",
    "                            evals=[(dtrain,'train'), (dval,'eval')], callbacks = [early_stop],\n",
    "                            verbose_eval = par.verbose_eval)\n",
    "\n",
    "            fea_imp = {k: v for k, v in sorted(bst.get_score(importance_type=par.importance_type).items(), key=lambda item: item[1], reverse=True)}\n",
    "            print(\"\\n\".join((f\"{k}: {np.round(v, 3)}\" ) for ind,(k, v) in enumerate(fea_imp.items()) if ind < 9))\n",
    "\n",
    "            val_pred.append(bst.predict(dval))\n",
    "            del dtrain, dval, early_stop;\n",
    "            gc.collect();\n",
    "            \n",
    "            with timer('aNet Inspiring'):\n",
    "                print(\"aNet Inspiring & Prediction ...\")\n",
    "                dbatrain = xgb.DMatrix(X_bat, label=y_bat[:, walk], missing=np.NaN, enable_categorical=True) \n",
    "                battle = xgb.train( params, dbatrain, bst.best_iteration)\n",
    "                test_alpha_pred.append(battle.predict(dtest))\n",
    "            del dbatrain, bst, battle;\n",
    "            gc.collect();\n",
    "            \n",
    "        if normalize:\n",
    "            print(f\"Validation mse : {mean_squared_error(np.expm1(y_val), np.expm1(np.array(val_pred).clip(0.).transpose()))}\")\n",
    "            print(f'SMAPE : {np.expm1(smape(y_val, np.array(val_pred).clip(0.).transpose()))}')\n",
    "            print(f'F A   : {np.expm1(mape_val(y_val, np.array(val_pred).clip(0.).transpose()))}\\n\\n')\n",
    "            score_mse.append(np.expm1(mape_val(y_val, np.array(val_pred).clip(0.).transpose())))\n",
    "        else:\n",
    "            print(f\"Validation mse: {mean_squared_error( y_val, np.array(val_pred).clip(0.).transpose())}\")\n",
    "            print(f'SMAPE : {smape(y_val, np.array(val_pred).clip(0.).transpose())}')\n",
    "            print(f'F A: {mape_val(y_val, np.array(val_pred).clip(0.).transpose())}\\n\\n')\n",
    "            score_mse.append(mape_val(y_val, np.array(val_pred).clip(0.).transpose()))\n",
    "            \n",
    "        dd_alpha = post_pro(test_alpha_pred, df, t_val_begin, Forecate_months, walk_target, normalize)\n",
    "        frames_alpha.append(dd_alpha)\n",
    "        \n",
    "    result_alpha = pd.concat(frames_alpha)\n",
    "    \n",
    "    print(f\"Final MSE: {np.average(score_mse, axis=0)}\")\n",
    "\n",
    "with timer('Simulation'):\n",
    "    simu(gid_map, result_alpha, postfix='xa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
